{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d27e8b2",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare the Dataset\n",
    "Organize Image Paths and Labels\n",
    "\n",
    "Use the metadata files (train.txt and test.txt) to create a Pandas DataFrame with image paths and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb4f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path      label\n",
      "0  /Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Proj...  apple_pie\n",
      "1  /Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Proj...  apple_pie\n",
      "2  /Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Proj...  apple_pie\n",
      "3  /Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Proj...  apple_pie\n",
      "4  /Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Proj...  apple_pie\n",
      "                                          image_path      label\n",
      "0  /Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Proj...  apple_pie\n",
      "1  /Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Proj...  apple_pie\n",
      "2  /Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Proj...  apple_pie\n",
      "3  /Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Proj...  apple_pie\n",
      "4  /Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Proj...  apple_pie\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "base_path = '/Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Project/Dataset/food-101/images/'\n",
    "meta_path = '/Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Project/Dataset/food-101/meta/'\n",
    "\n",
    "# Load training and testing data\n",
    "with open(meta_path + \"train.txt\", \"r\") as file:\n",
    "    train_images = file.read().splitlines()\n",
    "with open(meta_path + \"test.txt\", \"r\") as file:\n",
    "    test_images = file.read().splitlines()\n",
    "\n",
    "# Create DataFrames\n",
    "train_df = pd.DataFrame({\n",
    "    \"image_path\": [base_path + path + \".jpg\" for path in train_images],\n",
    "    \"label\": [path.split(\"/\")[0] for path in train_images]\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"image_path\": [base_path + path + \".jpg\" for path in test_images],\n",
    "    \"label\": [path.split(\"/\")[0] for path in test_images]\n",
    "})\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da556b8a",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing the Images\n",
    "\n",
    "### 1. Define Image Preprocessing Pipeline\n",
    "\n",
    "Resize images to a standard input size (e.g., 224x224 for models like ResNet or MobileNet).\n",
    "Normalize pixel values to a range of [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c960c73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75750 validated image filenames belonging to 101 classes.\n",
      "Found 25250 validated image filenames belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Parameters\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Define data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Normalize pixel values\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)  # Only rescale for test data\n",
    "\n",
    "# Flow images from DataFrame\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb5ac1",
   "metadata": {},
   "source": [
    "### 2. Encode Labels\n",
    "\n",
    "Convert labels to one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5d5809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Labels: ['apple_pie' 'baby_back_ribs' 'baklava' 'beef_carpaccio' 'beef_tartare']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df[\"label_encoded\"] = label_encoder.fit_transform(train_df[\"label\"])\n",
    "test_df[\"label_encoded\"] = label_encoder.transform(test_df[\"label\"])\n",
    "\n",
    "print(\"Encoded Labels:\", label_encoder.classes_[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ddfcef",
   "metadata": {},
   "source": [
    "## Step 4: Define the Model\n",
    "\n",
    "### 4.1.Use a Pre-trained Model (Transfer Learning)\n",
    "\n",
    "Use a pre-trained model like MobileNetV2 or ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12fa7781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Load pre-trained model\n",
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze pre-trained layers\n",
    "\n",
    "# Build model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(101, activation=\"softmax\", kernel_regularizer=\"l2\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Callbacks\n",
    "lr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0454c5",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model\n",
    "### 5.1 Fit the Model\n",
    "\n",
    "Train the model using the training data and validate on the testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shubhamgaur/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m  90/2367\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:26\u001b[0m 407ms/step - accuracy: 0.0074 - loss: 6.4172"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=30,  # Increase epochs\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faf97c7",
   "metadata": {},
   "source": [
    "### 5.2 Visualize Training Progress\n",
    "\n",
    "Plot accuracy and loss over epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Model Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf9ebf",
   "metadata": {},
   "source": [
    "## Step 6: Save and Evaluate the Model\n",
    "\n",
    "### 6.1 Save the Trained Model\n",
    "\n",
    "Save the model for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca513af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"food101_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f49fd",
   "metadata": {},
   "source": [
    "### 6.2 Evaluate on Test Data\n",
    "\n",
    "Evaluate the model’s performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f952185",
   "metadata": {},
   "source": [
    "## Step 7: Predict on New Images\n",
    "\n",
    "### 7.1 Load the Saved Model\n",
    "Load the model and predict on new images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4546f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "model = load_model(\"food101_model.keras\")\n",
    "\n",
    "\n",
    "# Load and preprocess a single image\n",
    "img = load_img('/Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Project/Dataset/food-101/images/apple_pie/3917257.jpg', target_size=(224, 224))\n",
    "img_array = img_to_array(img) / 255.0\n",
    "img_array = img_array.reshape(1, 224, 224, 3)\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = label_encoder.inverse_transform([predictions.argmax()])\n",
    "print(\"Predicted Class:\", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213e480",
   "metadata": {},
   "source": [
    "## 2. USDA FoodData Central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70420d95",
   "metadata": {},
   "source": [
    "### Step 1: Load the Data\n",
    "Read the CSV file into a Pandas DataFrame and inspect the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d63428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Project/Dataset/USDA FoodData/fda_approved_food_items_w_nutrient_info.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display column information\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6f429",
   "metadata": {},
   "source": [
    "### Step 2: Handle Missing Values\n",
    "Inspect and handle missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b1d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 50% missing values\n",
    "threshold = len(data) * 0.5\n",
    "data = data.dropna(axis=1, thresh=threshold)\n",
    "\n",
    "# Fill remaining missing values with 0 or other appropriate placeholders\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cfb6c1",
   "metadata": {},
   "source": [
    "### Step 3: Rename Columns\n",
    "Rename columns for easier access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for consistency and usability\n",
    "data = data.rename(columns={\n",
    "    \"fdc_id\": \"FDC_ID\",\n",
    "    \"brand_owner\": \"Brand\",\n",
    "    \"description\": \"Description\",\n",
    "    \"ingredients\": \"Ingredients\",\n",
    "    \"gtin_upc\": \"UPC\",\n",
    "    \"serving_size\": \"ServingSize\",\n",
    "    \"serving_size_unit\": \"ServingUnit\",\n",
    "    \"branded_food_category\": \"FoodCategory\",\n",
    "    \"modified_date\": \"ModifiedDate\",\n",
    "    \"available_date\": \"AvailableDate\",\n",
    "    \"Energy-KCAL\": \"Calories\",\n",
    "    \"Protein-G\": \"Protein\",\n",
    "    \"Total lipid (fat)-G\": \"Fat\",\n",
    "    \"Carbohydrate, by difference-G\": \"Carbohydrates\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158003b",
   "metadata": {},
   "source": [
    "### Step 4: Convert Data Types\n",
    "Convert data types for numerical and date columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97efd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "data[\"ModifiedDate\"] = pd.to_datetime(data[\"ModifiedDate\"], errors=\"coerce\")\n",
    "data[\"AvailableDate\"] = pd.to_datetime(data[\"AvailableDate\"], errors=\"coerce\")\n",
    "\n",
    "# Convert numeric columns to appropriate data types\n",
    "numeric_columns = [\n",
    "    \"ServingSize\", \"Calories\", \"Protein\", \"Fat\", \"Carbohydrates\"\n",
    "]\n",
    "data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Fill any remaining NaN values in numeric columns\n",
    "data[numeric_columns] = data[numeric_columns].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291e80f",
   "metadata": {},
   "source": [
    "### Step 5: Filter and Select Relevant Columns\n",
    "Drop irrelevant columns or focus only on required fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "data = data[[\n",
    "    \"FDC_ID\", \"Brand\", \"Description\", \"Ingredients\", \"UPC\",\n",
    "    \"ServingSize\", \"ServingUnit\", \"FoodCategory\", \"Calories\",\n",
    "    \"Protein\", \"Fat\", \"Carbohydrates\", \"ModifiedDate\", \"AvailableDate\"\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef75e8",
   "metadata": {},
   "source": [
    "### Step 6: Remove Duplicates\n",
    "Remove duplicate rows if any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa2f778",
   "metadata": {},
   "source": [
    "### Step 7: Save the Preprocessed Data\n",
    "Save the cleaned data into a new CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new file\n",
    "output_file = \"/Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Project/Dataset/USDA FoodData/cleaned_food_data.csv\"\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48419cf3",
   "metadata": {},
   "source": [
    "### Step 8: Validate the Cleaned Data\n",
    "Inspect the final cleaned dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect the cleaned data\n",
    "cleaned_data = pd.read_csv(output_file)\n",
    "print(cleaned_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943012a",
   "metadata": {},
   "source": [
    "## Implementation Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab0c66",
   "metadata": {},
   "source": [
    "### Step 1: Frontend for Uploading Image\n",
    "\n",
    "Use Streamlit to create the image upload interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from PIL import Image\n",
    "\n",
    "# Upload an image\n",
    "st.title(\"NutriVision\")\n",
    "uploaded_file = st.file_uploader(\"Upload a food image\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    image = Image.open(uploaded_file)\n",
    "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "    st.write(\"Analyzing the image...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b404fc",
   "metadata": {},
   "source": [
    "### Step 2: Run Food-101 Model\n",
    "Load and run the pre-trained Food-101 model to predict the food class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fbff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('/Users/shubhamgaur/Desktop/NU/Sem4/Gen AI/Project/food101_model.keras')\n",
    "\n",
    "# Preprocess the uploaded image for Food-101\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((224, 224))  # Resize to model input size\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image) / 255.0  # Normalize\n",
    "    image = tf.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Predict the food class\n",
    "if uploaded_file:\n",
    "    processed_image = preprocess_image(image)\n",
    "    prediction = model.predict(processed_image)\n",
    "    predicted_class = prediction.argmax(axis=-1)[0]  # Get the predicted class index\n",
    "    st.write(f\"Predicted Food: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678db862",
   "metadata": {},
   "source": [
    "### Step 3: Query USDA FoodData Central\n",
    "Search for the predicted class in the USDA dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ee73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned USDA dataset\n",
    "usda_data = pd.read_csv(\"path_to_cleaned_usda_data.csv\")\n",
    "\n",
    "# Search for the predicted food in the USDA dataset\n",
    "def search_usda(predicted_food, usda_data):\n",
    "    # Filter rows containing the predicted food in the Description or FoodCategory\n",
    "    matches = usda_data[\n",
    "        usda_data[\"Description\"].str.contains(predicted_food, case=False, na=False)\n",
    "        | usda_data[\"FoodCategory\"].str.contains(predicted_food, case=False, na=False)\n",
    "    ]\n",
    "    return matches\n",
    "\n",
    "# Get matching entries\n",
    "matches = search_usda(predicted_class, usda_data)\n",
    "\n",
    "# Display top match (if available)\n",
    "if not matches.empty:\n",
    "    top_match = matches.iloc[0]\n",
    "    st.write(\"Matched Food Item:\", top_match[\"Description\"])\n",
    "    st.write(\"Nutritional Information:\")\n",
    "    st.write(f\"Calories: {top_match['Calories']} kcal\")\n",
    "    st.write(f\"Protein: {top_match['Protein']} g\")\n",
    "    st.write(f\"Fat: {top_match['Fat']} g\")\n",
    "    st.write(f\"Carbohydrates: {top_match['Carbohydrates']} g\")\n",
    "else:\n",
    "    st.write(\"No matching food item found in the USDA dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0782581b",
   "metadata": {},
   "source": [
    "### Step 4: Add Generative AI Insights (Optional)\n",
    "Use a language model to generate personalized suggestions based on the nutritional data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa490ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a text generation model\n",
    "generator = pipeline(\"text-generation\", model=\"gpt-2\")\n",
    "\n",
    "# Generate dietary insights\n",
    "if not matches.empty:\n",
    "    nutrition_text = f\"This {predicted_class} contains {top_match['Calories']} kcal, {top_match['Protein']} g protein, {top_match['Fat']} g fat, and {top_match['Carbohydrates']} g carbohydrates.\"\n",
    "    suggestion = generator(f\"{nutrition_text} Provide dietary advice:\", max_length=50, num_return_sequences=1)\n",
    "    st.write(\"Dietary Insight:\")\n",
    "    st.write(suggestion[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356e4727",
   "metadata": {},
   "source": [
    "End-to-End Workflow\n",
    "\n",
    "User uploads an image.\n",
    "\n",
    "Image is analyzed by the Food-101 model to predict the food class.\n",
    "\n",
    "USDA FoodData Central is queried for the nutritional information of the predicted class.\n",
    "\n",
    "The results (nutritional information) are displayed.\n",
    "\n",
    "(Optional) Generative AI provides additional dietary insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b822d",
   "metadata": {},
   "source": [
    "Next Steps\n",
    "\n",
    "Integrate Code: Combine the frontend, model prediction, and USDA dataset query.\n",
    "\n",
    "Test the Pipeline: Test with a variety of food images to ensure accurate predictions and USDA matches.\n",
    "\n",
    "Refine Matching Logic: Improve the search function for better matching between Food-101 classes and USDA dataset entries.\n",
    "\n",
    "Add Features (Optional): Allow users to edit serving size and recalculate nutrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2f786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ce102",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the text generation pipeline with authentication\n",
    "generator = pipeline(\"text-generation\", model=\"gpt-2\", use_auth_token=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f515935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
